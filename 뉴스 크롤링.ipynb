{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889cf03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "키워드 입력 >전기차\n",
      "****날짜는 YYYY.MM.DD 형식으로 입력****\n",
      "시작일 입력>2021.08.05\n",
      "종료일 입력>2021.09.05\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "keyword = input(\"키워드 입력 >\")\n",
    "print(\"****날짜는 YYYY.MM.DD 형식으로 입력****\")\n",
    "sta_date = input(\"시작일 입력>\")\n",
    "end_date = input(\"종료일 입력>\")\n",
    "\n",
    "def news_counter():\n",
    "    pagenum = 400 #네이버는 한페이지당 10건, 총 4000건의 기사만 보여줌\n",
    "    for i in range(pagenum,0,-1):\n",
    "        pagination = 10*(i-1)+1\n",
    "        URL = f\"https://search.naver.com/search.naver?&where=news&query={keyword}&sm=tab_pge&sort=1&photo=0&field=0&reporter_article=&pd=3&ds={sta_date}&de={end_date}&docid=&nso=so:dd,p:from20200903to20210111,a:all&mynews=0&start={pagination}&refresh_start=0\"\n",
    "        result = requests.get(URL)\n",
    "        soup = BeautifulSoup(result.text, \"html.parser\")\n",
    "        results = soup.find(\"div\",{\"class\":\"group_news\"})\n",
    "        if results is None:\n",
    "            print(pagenum, \"페이지 기사 없음\")\n",
    "          # print(URL)\n",
    "            pagenum -= 1\n",
    "        else:\n",
    "            li_tag = soup.find_all(\"li\", {\"class\":\"bx\"})\n",
    "        for i in li_tag:\n",
    "            try:\n",
    "                numb = i.attrs['id']\n",
    "                numb = numb.lstrip('sp_nws')\n",
    "                print(numb)\n",
    "            # print(URL)\n",
    "            except KeyError:\n",
    "                return None\n",
    "print(news_counter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e006c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 키워드를 입력해주세요d\n",
      "필요한 뉴스기사의 숫자를 입력해주세요d\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m         page_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m news_df\n\u001b[1;32m---> 34\u001b[0m \u001b[43mNews\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mNews\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m검색 키워드를 입력해주세요\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m keyword \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote(keyword) \u001b[38;5;66;03m#퍼센트인코딩 #URL에 문자를 표현하는 인코딩방법(URL에 한글이 섞이면 오류 발생)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m필요한 뉴스기사의 숫자를 입력해주세요\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m news_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[0;32m     17\u001b[0m page_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'd'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib\n",
    "import urllib.request as rq\n",
    "import pandas as pd\n",
    "\n",
    "global news_df\n",
    "\n",
    "def News():\n",
    "    global keyword, num, news_df, url,page_num\n",
    "    \n",
    "    keyword = input('검색 키워드를 입력해주세요')\n",
    "    keyword = urllib.parse.quote(keyword) #퍼센트인코딩 #URL에 문자를 표현하는 인코딩방법(URL에 한글이 섞이면 오류 발생)\n",
    "    num = int(input('필요한 뉴스기사의 숫자를 입력해주세요'))\n",
    "    \n",
    "    news_df = pd.DataFrame(columns=['title','url']) \n",
    "    \n",
    "    page_num=1\n",
    "    i=0 #크롤링한 기사의 수\n",
    "    while num > i:\n",
    "        url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query='+keyword+'&start='+str(page_num)\n",
    "        html = rq.urlopen(url)\n",
    "        bs = BeautifulSoup(html,'html.parser')\n",
    "        texts = bs.find_all(class_='news_tit')\n",
    "\n",
    "        for text in texts:\n",
    "            news_df.loc[i,'title'] = text.get_text()\n",
    "            news_df.loc[i,'url'] = text['href']\n",
    "            i +=1\n",
    "            if i == num:\n",
    "                break\n",
    "        page_num +=10\n",
    "    return news_df\n",
    "\n",
    "News()\n",
    "\n",
    "# 청소년 도박 원인\n",
    "# 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75629a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m news_df\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#검색키워드, 제외키워드, num, start_date, end_date \u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# News('전기차','친환경', 5,'2019.01.01','2019.12.31')\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# News('도박','공무원', 1000,'2020.01.01','2020.12.31')\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# News('도박','이재명', 1000,'2021.01.01','2021.12.31')\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mNews\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m전기차\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m친환경\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022.07.01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2022.07.31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mNews\u001b[1;34m(keyword, ex_keyword, num, start_date, end_date)\u001b[0m\n\u001b[0;32m     19\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://search.naver.com/search.naver?where=news&sm=tab_jum&query=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mkeyword\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ex_keyword \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&photo=3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&pd=3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&ds=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mstart_date\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&de=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mend_date\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&start=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(page_num)\n\u001b[0;32m     20\u001b[0m html \u001b[38;5;241m=\u001b[39m rq\u001b[38;5;241m.\u001b[39murlopen(url)\n\u001b[1;32m---> 21\u001b[0m bs \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m texts \u001b[38;5;241m=\u001b[39m bs\u001b[38;5;241m.\u001b[39mfind_all(class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_tit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\site-packages\\bs4\\__init__.py:312\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;241m=\u001b[39m parse_only\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m     markup \u001b[38;5;241m=\u001b[39m \u001b[43mmarkup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    314\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_is_url(markup):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readall_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\http\\client.py:573\u001b[0m, in \u001b[0;36mHTTPResponse._readall_chunked\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 573\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\http\\client.py:556\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 556\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\http\\client.py:516\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cakd7\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib\n",
    "import urllib.request as rq\n",
    "import pandas as pd\n",
    "\n",
    "global news_df, keyword\n",
    "\n",
    "def News(keyword, ex_keyword, num, start_date, end_date):\n",
    "    global news_df, url,page_num\n",
    "    \n",
    "    keyword = urllib.parse.quote(keyword) #퍼센트인코딩 #URL에 문자를 표현하는 인코딩방법(URL에 한글이 섞이면 오류 발생)\n",
    "    ex_keyword = urllib.parse.quote(ex_keyword) #퍼센트인코딩 #URL에 문자를 표현하는 인코딩방법(URL에 한글이 섞이면 오류 발생)\n",
    "    \n",
    "    news_df = pd.DataFrame(columns=['title','url']) \n",
    "    \n",
    "    page_num=1\n",
    "    i=0 #크롤링한 기사의 수\n",
    "    while num > i:\n",
    "        url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query='+keyword+ '+' + ex_keyword + '&photo=3'+'&pd=3'+ '&ds='+start_date+'&de='+end_date+'&start='+str(page_num)\n",
    "        html = rq.urlopen(url)\n",
    "        bs = BeautifulSoup(html,'html.parser')\n",
    "        texts = bs.find_all(class_='news_tit')\n",
    "\n",
    "        for text in texts:\n",
    "            news_df.loc[i,'title'] = text.get_text()\n",
    "            news_df.loc[i,'url'] = text['href']\n",
    "            i +=1\n",
    "            if i == num:\n",
    "                break\n",
    "        page_num +=10\n",
    "    return news_df\n",
    "\n",
    "#검색키워드, 제외키워드, num, start_date, end_date \n",
    "# News('전기차','친환경', 5,'2019.01.01','2019.12.31')\n",
    "# News('도박','공무원', 1000,'2020.01.01','2020.12.31')\n",
    "# News('도박','이재명', 1000,'2021.01.01','2021.12.31')\n",
    "News('전기차','친환경', 4000,'2022.07.01','2022.07.31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcff3ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>기아·SK이노 ‘전기차 배터리 순환경제’ 구축한다</td>\n",
       "      <td>http://news.heraldcorp.com/view.php?ud=2021042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기아-SK이노, 전기차 배터리 순환경제 본격 시동</td>\n",
       "      <td>https://view.asiae.co.kr/article/2021042908240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기아·SK이노 ‘전기차 배터리 재활용 협력’ 본격화</td>\n",
       "      <td>http://news.kmib.co.kr/article/view.asp?arcid=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SK이노·SK렌터카, '안전하게 오래 쓰는' 전기차 배터리 협업</td>\n",
       "      <td>https://www.sedaily.com/NewsView/22LAAL8QG3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>우리銀, '무공해 친환경 전기차' 도입 확대</td>\n",
       "      <td>https://view.asiae.co.kr/article/2021042709102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>전자·배터리 CEO \"차별화된 경쟁력으로 도전·혁신\"</td>\n",
       "      <td>http://www.fnnews.com/news/202101041755578264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>이재용 \"새로운 삼성 만들자\"…정의선 \"신성장 동력으로 대전환\"</td>\n",
       "      <td>https://www.hankyung.com/economy/article/20210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>CEO들의 신축년 경영화두 ‘위기 극복과 미래 준비’</td>\n",
       "      <td>http://www.munhwa.com/news/view.html?no=202101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>바이러스 진단키트 개발… ‘누리호’ 첫 발사… 한계 넘는 도전, 올해도 계속...</td>\n",
       "      <td>https://www.donga.com/news/article/all/2021010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>‘신재생 에너지’ 선점 나선 재계... 오너家 3~4세 '승부수'</td>\n",
       "      <td>http://www.edaily.co.kr/news/newspath.asp?news...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1814 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0                       기아·SK이노 ‘전기차 배터리 순환경제’ 구축한다   \n",
       "1                       기아-SK이노, 전기차 배터리 순환경제 본격 시동   \n",
       "2                      기아·SK이노 ‘전기차 배터리 재활용 협력’ 본격화   \n",
       "3               SK이노·SK렌터카, '안전하게 오래 쓰는' 전기차 배터리 협업   \n",
       "4                          우리銀, '무공해 친환경 전기차' 도입 확대   \n",
       "...                                             ...   \n",
       "1809                  전자·배터리 CEO \"차별화된 경쟁력으로 도전·혁신\"   \n",
       "1810            이재용 \"새로운 삼성 만들자\"…정의선 \"신성장 동력으로 대전환\"   \n",
       "1811                  CEO들의 신축년 경영화두 ‘위기 극복과 미래 준비’   \n",
       "1812  바이러스 진단키트 개발… ‘누리호’ 첫 발사… 한계 넘는 도전, 올해도 계속...   \n",
       "1813           ‘신재생 에너지’ 선점 나선 재계... 오너家 3~4세 '승부수'   \n",
       "\n",
       "                                                    url  \n",
       "0     http://news.heraldcorp.com/view.php?ud=2021042...  \n",
       "1     https://view.asiae.co.kr/article/2021042908240...  \n",
       "2     http://news.kmib.co.kr/article/view.asp?arcid=...  \n",
       "3           https://www.sedaily.com/NewsView/22LAAL8QG3  \n",
       "4     https://view.asiae.co.kr/article/2021042709102...  \n",
       "...                                                 ...  \n",
       "1809      http://www.fnnews.com/news/202101041755578264  \n",
       "1810  https://www.hankyung.com/economy/article/20210...  \n",
       "1811  http://www.munhwa.com/news/view.html?no=202101...  \n",
       "1812  https://www.donga.com/news/article/all/2021010...  \n",
       "1813  http://www.edaily.co.kr/news/newspath.asp?news...  \n",
       "\n",
       "[1814 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib\n",
    "import urllib.request as rq\n",
    "import pandas as pd\n",
    "\n",
    "global news_df, keyword\n",
    "\n",
    "def News(keyword, ex_keyword, start_date, end_date):\n",
    "    global news_df, url,page_num\n",
    "    \n",
    "    keyword = urllib.parse.quote(keyword) #퍼센트인코딩 #URL에 문자를 표현하는 인코딩방법(URL에 한글이 섞이면 오류 발생)\n",
    "    ex_keyword = urllib.parse.quote(ex_keyword) #퍼센트인코딩 #URL에 문자를 표현하는 인코딩방법(URL에 한글이 섞이면 오류 발생)\n",
    "    \n",
    "    news_df = pd.DataFrame(columns=['title','url']) \n",
    "    \n",
    "    i=0\n",
    "    page_num=1\n",
    "    a = 'continue'\n",
    "    while a == 'continue':\n",
    "        num=0\n",
    "        url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query='+keyword+ '+' + ex_keyword + '&photo=3'+'&pd=3'+ '&ds='+start_date+'&de='+end_date+'&start='+str(page_num)\n",
    "        html = rq.urlopen(url)\n",
    "        bs = BeautifulSoup(html,'html.parser')\n",
    "        texts = bs.find_all(class_='news_tit')\n",
    "#         print(texts)\n",
    "        for text in texts:\n",
    "            news_df.loc[i,'title'] = text.get_text()\n",
    "            news_df.loc[i,'url'] = text['href']\n",
    "            num +=1\n",
    "            i+=1\n",
    "        if num != 10:\n",
    "            a = 'stop'\n",
    "        else:\n",
    "            page_num +=10\n",
    "    return news_df\n",
    "\n",
    "#검색키워드, 제외키워드, start_date, end_date \n",
    "# News('전기차','친환경', 5,'2019.01.01','2019.12.31')\n",
    "# News('도박','공무원', 1000,'2020.01.01','2020.12.31')\n",
    "# News('도박','이재명', 1000,'2021.01.01','2021.12.31')\n",
    "News('전기차','친환경','2021.01.01','2021.05.01') #분기별 #2분이상 걸리면 무한루프임 ..ㅇㅅㅇ... 그기간을 일단 빼고하세용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b41990c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EC%A0%84%EA%B8%B0%EC%B0%A8+%EC%B9%9C%ED%99%98%EA%B2%BD&photo=3&pd=3&ds=2021.01.01&de=2021.02.01&start=551'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
